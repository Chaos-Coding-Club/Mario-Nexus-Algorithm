{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869aa469",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gym_super_mario_bros==7.3.0 nes_py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b62b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e8ef1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install stable-baselines3[extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2c60ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install stable-baselines3 --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c951564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for \n",
    "import csv\n",
    "# Used for sorting Mario's data later\n",
    "import numpy as np\n",
    "# Import the game\n",
    "import gym_super_mario_bros\n",
    "# Import the Joypad wrapper\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "# Import the SIMPLIFIED controls\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2547b834",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.wrappers import FrameStack, GrayScaleObservation\n",
    "\n",
    "from stable_baselines3.common.vec_env import VecFrameStack, DummyVecEnv\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fbb0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import os file for path management\n",
    "import os\n",
    "# import PPO for algos\n",
    "from stable_baselines3 import PPO\n",
    "# Import Base Callback for saving models\n",
    "from stable_baselines3.common.callbacks import BaseCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0acabb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create base environment\n",
    "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
    "# Simplify Controls\n",
    "env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
    "# Grayscale\n",
    "env = GrayScaleObservation(env, keep_dim=True)\n",
    "# Format it for the AI to understand\n",
    "env = DummyVecEnv([lambda: env])\n",
    "# Stack the frames\n",
    "env = VecFrameStack(env, 4, channels_order='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dbb2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Used for saving every check_freq iteration of the AI as it trains as well as picking the file location\n",
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "\n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d345a610",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = './train/'\n",
    "LOG_DIR = './logs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b96ab79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup model saving callback\n",
    "callback = TrainAndLoggingCallback(check_freq=10000, save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7da9f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the AI model started\n",
    "#model = PPO('CnnPolicy', env, verbose=1, tensorboard_log=LOG_DIR, learning_rate=0.000001, \n",
    "#            n_steps=512) \n",
    "\n",
    "\n",
    "model = PPO.load('./train/best_model_500000')\n",
    "print(f\"{model.policy.optimizer.param_groups[0]['lr']}\")\n",
    "#model.policy.optimizer.param_groups[0]['lr'] = 0.000001\n",
    "\n",
    "model.set_env(env)\n",
    "for param_group in model.policy.optimizer.param_groups:\n",
    "    print(f\"{model.policy.optimizer.param_groups[0]['lr']}\")\n",
    "    param_group['lr'] = .000001\n",
    "    print(f\"{model.policy.optimizer.param_groups[0]['lr']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd7a167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the AI model, this is where the AI model starts to learn\n",
    "\n",
    "model.learn(total_timesteps=500000,callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6495bbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('thisisatestmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbbab29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load('./train/best_model_40000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cde593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input/X Collector, picks the farthest iteration that Mario can make it and upload to a .csv file to give to server\n",
    "# record the data during the learning process\n",
    "#mario_positions = []\n",
    "#actions = []\n",
    "#done = False\n",
    "#state = env.reset()\n",
    "#while not done:\n",
    "    # take an action using the learned model\n",
    "#    action, _states = model.predict(state)\n",
    "#    state, reward, done, info = env.step(action)\n",
    "\n",
    "    # record Mario's position, and the taken actions\n",
    "#    mario_x_position = info[0]['x_pos']\n",
    "#    mario_positions.append(mario_x_position)\n",
    "#    actions.append(action)\n",
    "#    env.render()\n",
    "#    if done:\n",
    "#        print(\"done\")\n",
    "#        env.reset()\n",
    "\n",
    "# find the step at which Mario got the farthest\n",
    "#farthest_step = np.argmax(mario_positions)\n",
    "#farthest_position = mario_positions[farthest_step]\n",
    "\n",
    "\n",
    "\n",
    "#print(f\"Mario's farthest position: {farthest_position}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c0c4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory to store the CSV file\n",
    "#if not os.path.exists(\"data\"):\n",
    "#    os.makedirs(\"data\")\n",
    "\n",
    "# Open the CSV file in write mode\n",
    "\n",
    "#with open(os.path.join(\"data\", \"data.csv\"), \"w\") as file:\n",
    "    #Get filepath for csv formatting\n",
    "#    file_path = os.path.join(\"data\", \"data.csv\")\n",
    "    \n",
    "    # Write the variable values as a row in the CSV file\n",
    "#    file.write(f\"{farthest_position}\")\n",
    "    \n",
    "#    with open(file_path, 'w', newline='') as csvfile:\n",
    "#        writer = csv.writer(csvfile)\n",
    "#        for elem in actions:\n",
    "#            writer.writerow(elem)\n",
    "\n",
    "#with open(file_path, mode='r') as csvfile:\n",
    "#    reader = csv.reader(csvfile)\n",
    "\n",
    "    # skip the first row (header row)\n",
    "#    next(reader)\n",
    "#    for row in reader:\n",
    "#        # convert the string values to integers\n",
    "#        inputs = [int(val) for val in row]\n",
    "#        if inputs:\n",
    "#            state, reward, done, info = env.step(inputs)\n",
    "#        \n",
    "#        if info[0]['x_pos'] == farthest_position:\n",
    "#            done = True\n",
    "#        env.render()\n",
    "#        if done:\n",
    "#            state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd84a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the game\n",
    "state = env.reset()\n",
    "# Loop through the game\n",
    "while True: \n",
    "    action, _ = model.predict(state)\n",
    "    state, reward, done, info = env.step(action)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf72849",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
