{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869aa469",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gym_super_mario_bros==7.3.0 nes_py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b62b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e8ef1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install stable-baselines3[extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c951564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Import the game\n",
    "import gym_super_mario_bros\n",
    "# Import the Joypad wrapper\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "# Import the SIMPLIFIED controls\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2547b834",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.wrappers import FrameStack, GrayScaleObservation\n",
    "\n",
    "from stable_baselines3.common.vec_env import VecFrameStack, DummyVecEnv\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0acabb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create base environment\n",
    "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
    "# Simplify Controls\n",
    "env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
    "# Grayscale\n",
    "env = GrayScaleObservation(env, keep_dim=True)\n",
    "# Format it for the AI to understand\n",
    "env = DummyVecEnv([lambda: env])\n",
    "# Stack the frames\n",
    "env = VecFrameStack(env, 4, channels_order='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25fbb0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import os file for path management\n",
    "import os\n",
    "# import PPO for algos\n",
    "from stable_baselines3 import PPO\n",
    "# Import Base Callback for saving models\n",
    "from stable_baselines3.common.callbacks import BaseCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dbb2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "\n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d345a610",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = './train/'\n",
    "LOG_DIR = './logs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b96ab79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup model saving callback\n",
    "callback = TrainAndLoggingCallback(check_freq=10000, save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7da9f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the AI model started\n",
    "model = PPO('CnnPolicy', env, verbose=1, tensorboard_log=LOG_DIR, learning_rate=0.00005, \n",
    "            n_steps=512) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd7a167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the AI model, this is where the AI model starts to learn\n",
    "model.learn(total_timesteps=100000, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6495bbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('thisisatestmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbbbab29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load('./train/best_model_200000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2f94a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbf72849",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\owenf\\anaconda3\\lib\\site-packages\\gym_super_mario_bros\\smb_env.py:148: RuntimeWarning: overflow encountered in ubyte_scalars\n",
      "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mario's farthest position: 315 at step 215\n",
      "Action taken at farthest position: [1]\n"
     ]
    }
   ],
   "source": [
    "# Input/X Collector, picks the farthest iteration that Mario can make it and upload to a .csv file to give to server\n",
    "# record the data during the learning process\n",
    "mario_positions = []\n",
    "actions = []\n",
    "\n",
    "\n",
    "for i in range(1000):\n",
    "    # take an action using the learned model\n",
    "    action, _states = model.predict(state)\n",
    "    state, reward, done, info = env.step(action)\n",
    "\n",
    "    # record Mario's position, and the taken actions\n",
    "    mario_x_position = info[0]['x_pos']\n",
    "    mario_positions.append(mario_x_position)\n",
    "    actions.append(action)\n",
    "\n",
    "# find the step at which Mario got the farthest\n",
    "farthest_step = np.argmax(mario_positions)\n",
    "farthest_position = mario_positions[farthest_step]\n",
    "farthest_action = actions[farthest_step]\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Mario's farthest position: {farthest_position} at step {farthest_step}\")\n",
    "print(f\"Action taken at farthest position: {farthest_action}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b744d544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory to store the CSV file\n",
    "if not os.path.exists(\"data\"):\n",
    "    os.makedirs(\"data\")\n",
    "\n",
    "# Open the CSV file in write mode\n",
    "with open(os.path.join(\"data\", \"data.csv\"), \"w\") as file:\n",
    "    # Write the variable values as a row in the CSV file\n",
    "    file.write(f\"{farthest_step},{farthest_action}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ff6b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the game \n",
    "state = env.reset()\n",
    "# Loop through the game\n",
    "counter = 0\n",
    "while True: \n",
    "    action, _ = model.predict(state)\n",
    "    state, reward, done, info = env.step(action)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd75943",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
